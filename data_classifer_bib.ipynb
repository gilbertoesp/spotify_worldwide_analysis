{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-173ccef09b83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import pandas as pd #Dataframe, Series\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import graphviz\n",
    "import pydotplus\n",
    "import io\n",
    "\n",
    "from scipy import misc\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "sp = spotipy.Spotify() \n",
    "from spotipy.oauth2 import SpotifyClientCredentials \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Login\n",
    "\n",
    "- Once you run this it will redirect you to another page, copy the url and paste it into the dialog box that will pop up below.\n",
    "- If you get a bad request the first time and you logged in, just run it again and use the new link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cid =\"0cadd882a6ab4ff485c80b8b02aa3b0c\" \n",
    "secret = \"04d0f737e18a4a92abee1da25d70766b\"\n",
    "username = \"\"\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret) \n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "scope = 'user-library-read playlist-read-private'\n",
    "token = util.prompt_for_user_token(username, scope)\n",
    "\n",
    "if token:\n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "else:\n",
    "    print(\"Can't get token for\", username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data to the Model\n",
    "- You need to include the user you want to get the playlist from as well as the playlist id's of your good and bad playlists.\n",
    "- To do this go to your good and bad playlists and copy the links.\n",
    "    - An example spotify link: https://open.spotify.com/user/1287242681/playlist/5OdH7PmotfAO7qDGxKdw3J\n",
    "    - The user is the number after user/ and the playlist id is after the playlist/.\n",
    "\n",
    "- The method signature is sp.user_playlist('user', 'playlist_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_playlist = sp.user_playlist(\"1287242681\", \"5OdH7PmotfAO7qDGxKdw3J\")\n",
    "bad_playlist = sp.user_playlist(\"1287242681\", \"3ySDAXYGUwRrp8C4ejIm9m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the good song id's out of the good playlists, need it for the audio features call.\n",
    "good_tracks = good_playlist[\"tracks\"]\n",
    "good_songs = good_tracks[\"items\"] \n",
    "while good_tracks['next']:\n",
    "    good_tracks = sp.next(good_tracks)\n",
    "    for item in good_tracks[\"items\"]:\n",
    "        good_songs.append(item)\n",
    "good_ids = [] \n",
    "print(len(good_songs))\n",
    "for i in range(len(good_songs)- 500):\n",
    "    good_ids.append(good_songs[i]['track']['id'])\n",
    "good_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now do the same thing for the bad playlist\n",
    "bad_tracks = bad_playlist[\"tracks\"]\n",
    "bad_songs = bad_tracks[\"items\"] \n",
    "while bad_tracks['next']:\n",
    "    bad_tracks = sp.next(bad_tracks)\n",
    "    for item in bad_tracks[\"items\"]:\n",
    "        bad_songs.append(item)\n",
    "bad_ids = [] \n",
    "print(len(bad_songs))\n",
    "for i in range(len(bad_songs)):\n",
    "    bad_ids.append(bad_songs[i]['track']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_artist_pop = []\n",
    "bad_artist_pop = []\n",
    "for i in range(0,len(good_tracks)):\n",
    "    print(good_tracks[])\n",
    "    #good_artist_pop.append(sp.artist(good_tracks[i]['track']['artists'][0]['id'])['popularity'])\n",
    "    \n",
    "#for track in bad_tracks:\n",
    " #   popularity = sp.artist(track['track']['artists'][0]['id'])['popularity']\n",
    "  #  bad_artist_pop.append(populartiy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Here is where we get all of the audio_features for the tracks on the good and bad playlists.\n",
    "features = []\n",
    "inSavedTracks = []\n",
    "j = 0\n",
    "for i in range(0,len(good_ids),50):\n",
    "    audio_features = sp.audio_features(good_ids[i:i+50])\n",
    "    for track in audio_features:\n",
    "        features.append(track)\n",
    "        track = good_songs[j]\n",
    "        j= j+1\n",
    "        features[-1]['trackPopularity'] = track['track']['popularity']\n",
    "        features[-1]['artistPopularity'] = sp.artist(track['track']['artists'][0]['id'])['popularity']\n",
    "        features[-1]['target'] = 1\n",
    "j = 0\n",
    "for i in range(0,len(bad_ids),50):\n",
    "    audio_features = sp.audio_features(bad_ids[i:i+50])\n",
    "    for track in audio_features:\n",
    "        features.append(track)\n",
    "        track = good_songs[j]\n",
    "        j= j+1\n",
    "        features[-1]['trackPopularity'] = track['track']['popularity']\n",
    "        features[-1]['artistPopularity'] = sp.artist(track['track']['artists'][0]['id'])['popularity']\n",
    "        features[-1]['target'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Data Modeling\n",
    "- Now that we have the data on what songs you like and don't like let's visualize some of that info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainingData = pd.DataFrame(features)\n",
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In training this classifier, we need so split our data into training and testing data so our classifier has things to train on and then test if it is right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(trainingData, test_size = 0.15)\n",
    "print(\"Training size: {}, Test size: {}\".format(len(train),len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom Color Palette for graphs\n",
    "red_blue = ['#19B5FE', '#EF4836']\n",
    "palette = sns.color_palette(red_blue)\n",
    "sns.set_palette(palette)\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) First, break out all of the data into positive and negative categories for all the features we want to compare\n",
    "\n",
    "Also, I know there has to be a better way of doing this, but copy paste is my friend. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tempo = trainingData[trainingData['target'] == 1]['tempo']\n",
    "neg_tempo = trainingData[trainingData['target'] == 0]['tempo']\n",
    "pos_dance = trainingData[trainingData['target'] == 1]['danceability']\n",
    "neg_dance = trainingData[trainingData['target'] == 0]['danceability']\n",
    "pos_duration = trainingData[trainingData['target'] == 1]['duration_ms']\n",
    "neg_duration = trainingData[trainingData['target'] == 0]['duration_ms']\n",
    "pos_loudness = trainingData[trainingData['target'] == 1]['loudness']\n",
    "neg_loudness = trainingData[trainingData['target'] == 0]['loudness']\n",
    "pos_speechiness = trainingData[trainingData['target'] == 1]['speechiness']\n",
    "neg_speechiness = trainingData[trainingData['target'] == 0]['speechiness']\n",
    "pos_valence = trainingData[trainingData['target'] == 1]['valence']\n",
    "neg_valence = trainingData[trainingData['target'] == 0]['valence']\n",
    "pos_energy = trainingData[trainingData['target'] == 1]['energy']\n",
    "neg_energy = trainingData[trainingData['target'] == 0]['energy']\n",
    "pos_acousticness = trainingData[trainingData['target'] == 1]['acousticness']\n",
    "neg_acousticness = trainingData[trainingData['target'] == 0]['acousticness']\n",
    "pos_key = trainingData[trainingData['target'] == 1]['key']\n",
    "neg_key = trainingData[trainingData['target'] == 0]['key']\n",
    "pos_instrumentalness = trainingData[trainingData['target'] == 1]['instrumentalness']\n",
    "neg_instrumentalness = trainingData[trainingData['target'] == 0]['instrumentalness']\n",
    "pos_popularity = trainingData[trainingData['target'] == 1]['trackPopularity']\n",
    "neg_popularity = trainingData[trainingData['target'] == 0]['trackPopularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos_popularity)\n",
    "print(neg_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.title(\"Song Tempo Like / Dislike Distribution\")\n",
    "pos_tempo.hist(alpha=0.7, bins=30, label='positive')\n",
    "neg_tempo.hist(alpha=0.7, bins=30, label='negative')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(15,15))\n",
    "\n",
    "#Danceability\n",
    "ax3 = fig2.add_subplot(331)\n",
    "ax3.set_xlabel('Danceability')\n",
    "ax3.set_ylabel('Count')\n",
    "ax3.set_title('Song Danceability Like Distribution')\n",
    "pos_dance.hist(alpha= 0.5, bins=30)\n",
    "ax4 = fig2.add_subplot(331)\n",
    "neg_dance.hist(alpha= 0.5, bins=30)\n",
    "\n",
    "#Duration_ms\n",
    "ax5 = fig2.add_subplot(332)\n",
    "ax5.set_xlabel('Duration')\n",
    "ax5.set_ylabel('Count')\n",
    "ax5.set_title('Song Duration Like Distribution')\n",
    "pos_duration.hist(alpha= 0.5, bins=30)\n",
    "ax6 = fig2.add_subplot(332)\n",
    "neg_duration.hist(alpha= 0.5, bins=30)\n",
    "\n",
    "#Loudness\n",
    "ax7 = fig2.add_subplot(333)\n",
    "ax7.set_xlabel('Loudness')\n",
    "ax7.set_ylabel('Count')\n",
    "ax7.set_title('Song Loudness Like Distribution')\n",
    "pos_loudness.hist(alpha= 0.5, bins=30)\n",
    "ax8 = fig2.add_subplot(333)\n",
    "neg_loudness.hist(alpha= 0.5, bins=30)\n",
    "\n",
    "#Speechiness\n",
    "ax9 = fig2.add_subplot(334)\n",
    "ax9.set_xlabel('Speechiness')\n",
    "ax9.set_ylabel('Count')\n",
    "ax9.set_title('Song Speechiness Like Distribution')\n",
    "pos_speechiness.hist(alpha= 0.5, bins=30)\n",
    "ax10 = fig2.add_subplot(334)\n",
    "neg_speechiness.hist(alpha= 0.5, bins=30)\n",
    "\n",
    "#Valence\n",
    "ax11 = fig2.add_subplot(335)\n",
    "ax11.set_xlabel('Valence')\n",
    "ax11.set_ylabel('Count')\n",
    "ax11.set_title('Song Valence Like Distribution')\n",
    "pos_valence.hist(alpha= 0.5, bins=30)\n",
    "ax12 = fig2.add_subplot(335)\n",
    "neg_valence.hist(alpha= 0.5, bins=30)\n",
    "\n",
    "#Energy\n",
    "ax13 = fig2.add_subplot(336)\n",
    "ax13.set_xlabel('Energy')\n",
    "ax13.set_ylabel('Count')\n",
    "ax13.set_title('Song Energy Like Distribution')\n",
    "pos_energy.hist(alpha= 0.5, bins=30)\n",
    "ax14 = fig2.add_subplot(336)\n",
    "neg_energy.hist(alpha= 0.5, bins=30)\n",
    "\n",
    "#Key\n",
    "ax15 = fig2.add_subplot(337)\n",
    "ax15.set_xlabel('Key')\n",
    "ax15.set_ylabel('Count')\n",
    "ax15.set_title('Song Key Like Distribution')\n",
    "pos_key.hist(alpha= 0.5, bins=30)\n",
    "ax16 = fig2.add_subplot(337)\n",
    "neg_key.hist(alpha= 0.5, bins=30)\n",
    "\n",
    "#Key\n",
    "ax15 = fig2.add_subplot(338)\n",
    "ax15.set_xlabel('Popularity')\n",
    "ax15.set_ylabel('Count')\n",
    "ax15.set_title('Popularity Distribution')\n",
    "pos_popularity.hist(alpha= 0.5, bins=30)\n",
    "ax16 = fig2.add_subplot(338)\n",
    "neg_popularity.hist(alpha= 0.5, bins=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wewh, now that we have graphs galore, lets actually get into some different classifiers and see how they preform!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the set of features that we want to look at\n",
    "features = [\"danceability\", \"loudness\", \"valence\", \"energy\", \"instrumentalness\", \"acousticness\", \"key\", \"speechiness\",\"duration_ms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split the data into x and y test and train sets to feed them into a bunch of classifiers!\n",
    "x_train = train[features]\n",
    "y_train = train[\"target\"]\n",
    "\n",
    "x_test = test[features]\n",
    "y_test = test[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) A Decision Tree Classifier\n",
    "- A decision tree classifier is often the easiest to visualize, so we will start with it first\n",
    "- All it is is pretty much a decision tree based off the features so you can trace the path down and visually see how it makes decisions. This is nice to visualize but it isn't all that good at predicting this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = DecisionTreeClassifier(min_samples_split=100)\n",
    "dt = c.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_tree(InputTree, features, path):\n",
    "    f = io.StringIO()\n",
    "    tree.export_graphviz(InputTree, out_file=f, feature_names=features)\n",
    "    pydotplus.graph_from_dot_data(f.getvalue()).write_png(path)\n",
    "    img = misc.imread(path)\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "    plt.imshow(img)\n",
    "show_tree(dt, features, \"dec_tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we will see how our different classifiers do, by predicting the results on the test data and then figuring out how well they did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = c.predict(x_test)\n",
    "score = accuracy_score(y_test, y_pred) * 100\n",
    "print(\"Accuracy using Decision Tree: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Bunch More Classifier Models\n",
    "- There are some of these that take a bunch of time to finish, I wouldnt recommend running all them unless you are really intrested in the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ones that take less time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(3)\n",
    "knn.fit(x_train, y_train)\n",
    "knn_pred = c.predict(x_test)\n",
    "score = accuracy_score(y_test, knn_pred) * 100\n",
    "print(\"Accuracy using Knn Tree: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(x_train, y_train)\n",
    "mlp_pred = mlp.predict(x_test)\n",
    "score = accuracy_score(y_test, mlp_pred) * 100\n",
    "print(\"Accuracy using mlp Tree: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "forest.fit(x_train, y_train)\n",
    "forest_pred = forest.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test, forest_pred) * 100\n",
    "print(\"Accuracy using random forest: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(x_train, y_train)\n",
    "ada_pred = ada.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test, ada_pred) * 100\n",
    "print(\"Accuracy using ada: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gauss = GaussianNB()\n",
    "gauss.fit(x_train, y_train)\n",
    "gauss_pred = gauss.predict(x_test)\n",
    "score = accuracy_score(y_test, gauss_pred)*100\n",
    "print(\"Accuracy using gauss: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=3, random_state=0)\n",
    "k_means.fit(x_train, y_train)\n",
    "predicted= k_means.predict(x_test)\n",
    "score = accuracy_score(y_test, predicted)*100\n",
    "print(\"Accuracy using Kmeans: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=.1, max_depth=1, random_state=0)\n",
    "gbc.fit(x_train, y_train)\n",
    "predicted = gbc.predict(x_test)\n",
    "score = accuracy_score(y_test, predicted)*100\n",
    "print(\"Accuracy using Gbc: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ones that take more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# qda = QuadraticDiscriminantAnalysis()\n",
    "# qda.fit(x_train, y_train)\n",
    "# qda_pred = qda.predict(x_test)\n",
    "# score = accuracy_score(y_test, qda_pred)*100\n",
    "# print(\"Accuracy using qda: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# svc_lin = SVC(kernel=\"linear\", C=0.025)\n",
    "# svc_lin.fit(x_train, y_train)\n",
    "# svc_pred = svc_lin.predict(x_test)\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# score = accuracy_score(y_test, svc_pred) * 100\n",
    "# print(\"Accuracy using svc linear: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# from sklearn.gaussian_process.kernels import RBF\n",
    "# gpc = GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True)\n",
    "# gpc.fit(x_train, y_train)\n",
    "# gpc_pred = gpc.predict(x_test)\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# score = accuracy_score(y_test, gpc_pred) * 100\n",
    "# print(\"Accuracy using gpc: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we should have a classifier with the highest accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Request to modify playlists\n",
    "username = \"1287242681\"\n",
    "scope = 'playlist-modify-private playlist-modify-public playlist-read-private user-library-read'\n",
    "token = util.prompt_for_user_token(username, scope)\n",
    "#Good Playlist\n",
    "if token:\n",
    "    sp = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to pick a playlist you want you classifier to find songs you like in...\n",
    "- Use the same thing you used to find the good and bad playlists to specify this new playlist you've taken an intrest in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "playlistToFindSongsYouLikeIn = sp.user_playlist(\"spotify\", \"37i9dQZEVXcFqDuJHHirGk\")\n",
    "\n",
    "newPlaylist_tracks = playlistToFindSongsYouLikeIn[\"tracks\"]\n",
    "newPlaylist_songs = newPlaylist_tracks[\"items\"] \n",
    "while newPlaylist_tracks['next']:\n",
    "    newPlaylist_tracks = sp.next(newPlaylist_tracks)\n",
    "    for song in newPlaylist_tracks[\"items\"]:\n",
    "        newPlaylist_songs.append(song)\n",
    "        \n",
    "newPlaylist_song_ids = [] \n",
    "print(len(newPlaylist_songs))\n",
    "for i in range(len(newPlaylist_songs)):\n",
    "    newPlaylist_song_ids.append(newPlaylist_songs[i]['track']['id'])\n",
    "    \n",
    "newPlaylist_features = []\n",
    "j = 0\n",
    "for i in range(0,len(newPlaylist_song_ids),50):\n",
    "    audio_features = sp.audio_features(newPlaylist_song_ids[i:i+50])\n",
    "    for track in audio_features:\n",
    "        track['song_title'] = newPlaylist_songs[j]['track']['name']\n",
    "        track['artist'] = newPlaylist_songs[j]['track']['artists'][0]['name']\n",
    "        j= j + 1\n",
    "        newPlaylist_features.append(track)\n",
    "print(len(newPlaylist_features))\n",
    "\n",
    "playlistToLookAtFeatures = pd.DataFrame(newPlaylist_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We just loaded in your new tracks and audio features for those tracks\n",
    "- Now all we have to do is find the highest accuracy value out of all you classifiers (for me it was gdc) and predict what we will have over the new playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick aside: you can put these into a new playlist as well, just use the sp.user_playlist_add_tracks function\n",
    "- The function looks like this user_playlist_add_tracks(\"username\", \"playlist_id\", \"track_id_to_add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = gbc.predict(playlistToLookAtFeatures[features])\n",
    "\n",
    "likedSongs = 0\n",
    "i = 0\n",
    "for prediction in pred:\n",
    "    if(prediction == 1):\n",
    "        print (\"Song: \" + playlistToLookAtFeatures[\"song_title\"][i] + \", By: \"+ playlistToLookAtFeatures[\"artist\"][i])\n",
    "        #sp.user_playlist_add_tracks(\"1287242681\", \"7eIX1zvtpZR3M3rYFVA7DF\", [test['id'][i]])\n",
    "        likedSongs= likedSongs + 1\n",
    "    i = i +1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There Ya Go!\n",
    "- This was my quick overview of my process of how I used classifiers and spoitfy to try and help me find tracks I might like in any playlist on spotify!\n",
    "- I want to make this tutorial less involved and figure out a way to make my classifiers better as well as using Tensorflow to make a model in order to do this for me."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
